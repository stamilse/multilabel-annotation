{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. length = low,medium,high\n",
    "1. subject/object/verb/adverb/adjective/abbrevation = yes,no\n",
    "1. voice = active,passive\n",
    "1. type of sentences = immperative, interrogative, exclamative, declarative, negative, affirmative etc.\n",
    "1. figures of speech = metaphor, simili, personification, idiom\n",
    "1. Tense = present, past, simple, participle, etc.\n",
    "1. Code Switching = yes, no\n",
    "1. Typos = yes, no\n",
    "1. Emojis = yes, no\n",
    "1. Homoglyphs = yes, no\n",
    "1. Special Characters = yes, no\n",
    "1. Grammatical Correctness = yes, no\n",
    "1. Clause = Dependent, independent, subordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp.add_pipe(nlp.create_pipe('sentencizer')) # Ref : https://spacy.io/api/sentencizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "rd_text = \"\"\n",
    "with open('RC_2005-12.json','r') as data_file:\n",
    "    for line in data_file:\n",
    "        data = json.loads(line)\n",
    "        rd_text = rd_text + data['body'] + \"\\n\"\n",
    "        \n",
    "#print(d_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_text0 = \"\"\n",
    "with open('sst_origtrainvoice.train.0.txt','r') as data_file:\n",
    "    f = data_file.readlines()\n",
    "    for line in f:\n",
    "        d_text0 = d_text0 + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_text1 = \"\"\n",
    "with open('sst_origtrainvoice.train.1.txt','r') as data_file:\n",
    "    f = data_file.readlines()\n",
    "    for line in f:\n",
    "        d_text1 = d_text1 + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calcVerb(text):\n",
    "    c=0\n",
    "    for word in text:\n",
    "        if(word.pos_=='VERB'):\n",
    "            c=c+1\n",
    "    if(c<3):\n",
    "        print(\"length is low\")\n",
    "    elif(c<6):\n",
    "        print(\"length is medium\")\n",
    "    else:\n",
    "        print(\"length is high\")\n",
    "\n",
    "text = \"Nice Place! The room was nice/clean.\\\n",
    "The location was great-connected to the mall.\\\n",
    "The lobby was a bit congested and loud.\\\n",
    "Great Hotel/Location I got a great rate on priceline for this hotel.\\\n",
    "Because I am a frequent Starwood (Shertaon Hotel Chain) guest, we were assigned a room in the North Tower for the Starwood Preferred Guests.\\\n",
    "The hallways don't look in very good shape, but the room was large, clean, and very comfortable.\\\n",
    "The hotel is well situated.\\\n",
    "You can eat in the Prudential Center mall at the Au Bon Pan or the Marche for breakfast.\\\n",
    "Much cheaper than in the hotel.\\\n",
    "Plus, the mall has Legal Seafoods - one of the best seafood restaurants in Boston.\\\n",
    "You can get to the T (Prudential Center) stop without going outside.\\\n",
    "The Upscale shops on Boylston is very close and the Boston Common is about one mile walk if you don't want to take the T.\\\n",
    "I would stay there again at twice the price. Good location! \\\n",
    "We stayed in this hotel on Aug 23-25 and Sept 6-7 again due to some business.\\\n",
    "The first time we stayed in the North Tower with 2 double beds.\\\n",
    "The room is very nice and the washroom is a bit old. We asked for the south tower the second time after seeing the other's comments on tripadvisor.\\\n",
    "Again we have 2 double beds and the room is a bit larger that the one in North tower.\\\n",
    "The bathroom is new except the bathtub and the wall tile \\\n",
    "(They must want to save money by renovating only half of the bathroom). \\\n",
    "Overall, the north tower has nicer elevator and hallways, but the size of the room can vary.\\\n",
    "It is a nice hotel at a good location.\\\n",
    "Nice hotel cons: parking is pricey (separate from hotel). \\\n",
    "Service is typical of huge convention style hotel.\\\n",
    "Pool/fitness center requires fee and looks pretty crowded.\\\n",
    "Pros: good location. Right next to big mall with nice stores and food.\\\n",
    "Walking distance to Newbury street (great stores, and food - high end). \\\n",
    "Very close to Charles R., and MIT/Harvard - good for a morning jog from the hotel)! \\\n",
    "Decent expedia pricing.\\\n",
    "Quilt and linens were new, but room itself had a dated look. \\\n",
    "1King room itself is quite large.\\\n",
    "Definitely a high usage place as nothing is really super-clean.\\\n",
    "One of the worst I stayed at this hotel for a conference in June 03. \\\n",
    "The first room I got, which was tiny, had a broken toilet.\\\n",
    "When I attempted to call the front desk I discovered the phones didn't work! \\\n",
    "The second room I got still had problems.\\\n",
    "The cold-water faucet in the bathroom sink didn't work, the towel rack in the bathroom had fallen off the wall and was lying on the floor under the sink, there were suspicious stains on the comforter, all the channels on the TV were fuzzy and the Internet connection was flaky (they actually tried to bill me for a service I didn't use). \\\n",
    "The service staff was slow to respond and down right rude in some cases.\\\n",
    "Finally it's been two months and they won't credit me the airline miles for my stay.\\\n",
    "This was one of the worst hotels I've ever had the misfortune to stay at.\"\n",
    "        \n",
    "for num,sentence in enumerate(doc.sents):\n",
    "    print(f'{num}: {sentence}')\n",
    "    calcVerb(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. subject/object/verb/adverb/adjective/abbrevation = yes,no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-44ec498e68e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'Startup companies create jobs and support innovation. Hilary supports entrepreneurship.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_ext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubject_verb_object_triples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textacy'"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "\n",
    "text = nlp(u'Startup companies create jobs and support innovation. Hilary supports entrepreneurship.')\n",
    "\n",
    "text_ext = textacy.extract.subject_verb_object_triples(text)\n",
    "\n",
    "#OR\n",
    "\n",
    "\"\"\"for word in document:\n",
    "    if(word.dep_=='nsubj'):\n",
    "        print(\"subject: \",word)\n",
    "    if(word.pos_=='VERB'):\n",
    "        print(\"verb: \",word)\n",
    "    if(word.dep_=='dobj'):\n",
    "        print(\"object: \",word)\n",
    "    if(word.pos_=='ADV'):\n",
    "        print(\"Adverb: \",word)\n",
    "    if(word.pos_=='ADJ'):\n",
    "        print(\"Adjective: \",word)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Type of Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarative sentence.\n"
     ]
    }
   ],
   "source": [
    "#IMPERATIVE SENTENCES\n",
    "matcher = Matcher(nlp.vocab)\n",
    "sent=(\"You are going to be a bear.\")\n",
    "document=nlp(sent)\n",
    "\n",
    "def func1(tagged):\n",
    "    if(tagged[-2]!=\"?\"):\n",
    "        if(tagged[1]==\"VB\" or tagged[1]==\"MD\"):\n",
    "            return True\n",
    "        \n",
    "tagged=tuple()\n",
    "for word in document:\n",
    "    tagged=tagged+((word.text,word.tag_))\n",
    "if func1(tagged):\n",
    "    print(\"imperative\")\n",
    "    \n",
    "\n",
    "#NEGATIVE\n",
    "def is_negative(matcher, doc, id, matches):\n",
    "    print(\"negative sentence\")\n",
    "matcher.add('ISNEG',is_negative,[{'DEP':'neg'}])\n",
    "matches = matcher(document)\n",
    "\n",
    "\n",
    "#EXCALMATIVE\n",
    "if(document[-1].pos_=='PUNCT'):\n",
    "    if(document[-1].text=='!'):\n",
    "        print(\"Exclamative sentence.\")\n",
    "\n",
    "\n",
    "#DECLARATIVE\n",
    "if(document[-1].pos_=='PUNCT'):\n",
    "    if(document[-1].text=='.'):\n",
    "        print(\"Declarative sentence.\")\n",
    "        \n",
    "\n",
    "#INTERROGATIVE\n",
    "if(document[-1].pos_=='PUNCT'):\n",
    "    if(document[-1].text=='?'):\n",
    "        print(\"Interrogative sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: a spooky yarn of demonic doings on the high seas that works better the less the brain is engaged .\n",
      "\n",
      "1: what little atmosphere is generated by the shadowy lighting  macabre sets  and endless rain is offset by the sheer ugliness of everything else .\n",
      "\n",
      "2: broomfield is energized by volletta wallace 's maternal fury  \n",
      "3: her fearlessness  and because of that  his film crackles .\n",
      "\n",
      "4: to say this was done better in wilder 's some like it hot is like saying the sun rises in the east .\n",
      "\n",
      "5: both shrill and soporific  and because everything is repeated five or six times  \n",
      "6: it can seem tiresomely simpleminded .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "7: an unholy mess  driven by the pathetic idea that if you shoot something on crummy-looking videotape  \n",
      "8: it must be labelled ` hip '  ` innovative ' and ` realistic ' .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "9: the biggest problem with roger avary 's uproar against the mpaa is that  even in all its director 's cut glory  \n",
      "10: he 's made a film that 's barely shocking  barely interesting and most of all  barely anything .\n",
      "\n",
      "11: it 's hard to imagine that even very small children will be impressed by this tired retread .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "12: staggers between flaccid satire and what is supposed to be madcap farce .\n",
      "\n",
      "13: little is done to support the premise other than fling gags at it to see which ones shtick .\n",
      "\n",
      "14: there is a real subject here  and it is handled with intelligence and care .\n",
      "with rare birds  as with the shipping news before it  an attempt is made to transplant a hollywood star into newfoundland 's wild soil -- and the rock once again resists the intrusion .\n",
      "aside from the fact that the film idiotically uses the website\n",
      "15: feardotcom.com or the improperly hammy performance from poor stephen rea  \n",
      "16: the film gets added disdain for the fact that it is nearly impossible to look at or understand .\n",
      "\n",
      "17: though an important political documentary  this does not really make the case the kissinger should be tried as a war criminal .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "18: the narrator and the other characters try to convince us that acting transfigures esther  \n",
      "19: but she 's never seen speaking on stage ; one feels cheated  and esther seems to remain an unchanged dullard .\n",
      "\n",
      "20: while some of the camera work is interesting  the film 's mid-to-low budget is betrayed by the surprisingly shoddy makeup work .\n",
      "\n",
      "21: what a vast enterprise has been marshaled in the service of such a minute idea .\n",
      "\n",
      "PRESENT PERFECT\n",
      "22: what 's needed so badly but what is virtually absent here is either a saving dark humor or the feel of poetic tragedy .\n",
      "\n",
      "23: partway through watching this saccharine  easter-egg-colored concoction  \n",
      "24: you realize that it is made up of three episodes of a rejected tv show .\n",
      "\n",
      "25: it 's sobering  particularly if anyone still thinks this conflict can be resolved easily  or soon .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "26: once one experiences mr.\n",
      "27: haneke 's own sadistic tendencies toward his audience  \n",
      "28: one is left with a sour taste in one 's mouth  and little else .\n",
      "\n",
      "29: the plot is nothing but boilerplate clichÃ©s from start to finish  and the script assumes that not only would subtlety be lost on the target audience  but that it 's also too stupid to realize that they 've already seen this exact same movie a hundred times\n",
      "tale will be all too familiar for anyone who 's seen george roy hill 's 1973 film  `` the sting . ''\n",
      "\n",
      "FUTURE SIMPLE\n",
      "30: a dull  somnambulant exercise in pretension whose pervasive quiet is broken by frequent outbursts of violence and noise .\n",
      "\n",
      "31: the only question ... is to determine how well the schmaltz is manufactured -- to assess the quality of the manipulative engineering .\n",
      "\n",
      "32: films are made of little moments .\n",
      "\n",
      "33: the metaphors are provocative  but too often  the viewer is left puzzled by the mechanics of the delivery .\n",
      "\n",
      "34: solondz may be convinced that he has something significant to say  \n",
      "FUTURE SIMPLE\n",
      "35: but he is n't talking a talk that appeals to me .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "36: one of those rare films that seems as though it was written for no one  but somehow manages to convince almost everyone that it was put on the screen  just for them .\n",
      "\n",
      "37: it 's supposed to be a humorous  all-too-human look at how hope can breed a certain kind of madness -- and strength -- but it never quite adds up .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "38: it 's only in fairy tales that princesses that are married for political reason\n",
      "39: live happily ever after .\n",
      "\n",
      "40: after an hour and a half of wondering -- sometimes amusedly  sometimes impatiently -- just what this strenuously unconventional movie is supposed to be  \n",
      "41: you discover that the answer is as conventional as can be .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "42: a behind the scenes look at the training and dedication that goes into becoming a world-class fencer and the champion that 's made a difference to nyc inner-city youth .\n",
      "\n",
      "43: this tale has been told and retold ; the races and rackets change  but the song remains the same .\n",
      "\n",
      "PRESENT PERFECT\n",
      "44: the leads we are given here are simply too bland to be interesting .\n",
      "\n",
      "45: the film is enriched by an imaginatively mixed cast of antic spirits  headed by christopher plummer as the subtlest and most complexly evil uncle ralph\n",
      "46: i 've ever seen in the many film and stage adaptations of the work .\n",
      "gussied up with so many distracting special effects and visual party tricks that it 's not clear whether we 're supposed to shriek or laugh .\n",
      "\n",
      "47: even if the enticing prospect of a lot of nubile young actors in a film about campus depravity did n't fade amid the deliberate  tiresome ugliness  \n",
      "48: it would be rendered tedious by avary 's failure to construct a story with even a trace of dramatic interest .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "49: this film was made by and for those folks who collect the serial killer cards and are fascinated by the mere suggestion of serial killers .\n",
      "\n",
      "50: the kind of trifle that date nights were invented for .\n",
      "were dylan thomas alive to witness first-time director ethan hawke 's strained chelsea walls  he might have been tempted to change his landmark poem to  ` do not go gentle into that good theatre . '\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE PERFECT\n",
      "PRESENT PERFECT\n",
      "51: it 's played in the most straight-faced fashion  with little humor to lighten things up .\n",
      "\n",
      "52: you 're not merely watching history  \n",
      "53: you 're engulfed by it .\n",
      "\n",
      "54: suffice to say its total promise is left slightly unfulfilled .\n",
      "\n",
      "55: a very familiar tale  one that 's been told by countless filmmakers about italian -  chinese -  irish -  \n",
      "56: latin -  indian\n",
      "57: -  russian - and other hyphenate american young men struggling to balance conflicting cultural messages .\n",
      "\n",
      "58: this insufferable movie is meant to make you think about existential suffering .\n",
      "\n",
      "59: will be far more interesting to the soderbergh faithful than it will be to the casual moviegoer who might be lured in by julia roberts ...\n",
      "... by the time it 's done with us  mira nair 's new movie has its audience giddy with the delight of discovery  of having been immersed in a foreign culture only to find that human nature is pretty much the same all over .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "60: it 's bedeviled by labored writing and slack direction .\n",
      "\n",
      "61: once again  the intelligence of gay audiences has been grossly underestimated  and a meaty plot and well-developed characters have been sacrificed for skin and flash that barely fizzle .\n",
      "\n",
      "PRESENT PERFECT\n",
      "PRESENT PERFECT\n",
      "62: you wo n't miss its messages  but you 'll be entertained as well .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "63: it 's lost the politics and the social observation and become just another situation romance about a couple of saps stuck in an inarticulate screenplay .\n",
      "\n",
      "64: an uneven look into a grim future that does n't come close to the level of intelligence and visual splendour that can be seen in other films based on philip k. dick stories .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "65: sc2 is an autopilot hollywood concoction lacking in imagination and authentic christmas spirit  \n",
      "66: yet it 's geared toward an audience full of masters of both .\n",
      "\n",
      "67: after collateral damage  you might imagine that most every aggrieved father clichÃ© has been unturned .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "PRESENT PERFECT\n",
      "68: we 're left with a story that tries to grab us  only to keep letting go at all the wrong moments .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "69: can be as tiresome as 9 seconds of jesse helms ' anti-\n",
      "FUTURE SIMPLE\n",
      "70: castro rhetoric  which are included\n",
      "to honestly address the flaws inherent in how medical aid is made available to american workers  a more balanced or fair portrayal of both sides will be needed .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "71: while general audiences might not come away with a greater knowledge of the facts of cuban music  \n",
      "FUTURE SIMPLE\n",
      "72: they 'll be treated to an impressive and highly entertaining celebration of its sounds .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "73: de ayala is required to supply too much of the energy in a film that is  overall  far too staid for its subject matter .\n",
      "\n",
      "74: shanghai ghetto should be applauded for finding a new angle on a tireless story  \n",
      "FUTURE SIMPLE\n",
      "75: but you might want to think twice before booking passage .\n",
      "\n",
      "76: every joke is repeated at least four times .\n",
      "\n",
      "77: outside of burger 's desire to make some kind of film  \n",
      "78: it 's really unclear why this project was undertaken\n",
      "\n",
      "79: morrissette has performed a difficult task indeed - he 's taken one of the world 's most fascinating stories and made it dull  lifeless  and irritating .\n",
      "\n",
      "PRESENT PERFECT\n",
      "80: i have to admit that i am baffled by jason x.\n",
      "watching e.t now  in an era dominated by cold  loud special-effects-laden extravaganzas  \n",
      "81: one is struck less by its lavish grandeur than by its intimacy and precision .\n",
      "\n",
      "82: given the fact that virtually no one is bound to show up at theatres for it  \n",
      "83: the project should have been made for the tube .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE PERFECT\n",
      "PRESENT PERFECT\n",
      "84: parker should be commended for taking a fresh approach to familiar material  but his determination to remain true to the original text leads him to adopt a somewhat mannered tone ... that ultimately dulls the human tragedy at the story 's core .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "85: perhaps the film should be seen as a conversation starter .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "86: the plot is plastered with one hollywood cliche after another  most of which involve precocious kids getting the better of obnoxious adults .\n",
      "\n",
      "87: the obnoxious special effects  the obligatory outbursts of flatulence and the incessant  so-five-minutes-ago pop music on the soundtrack overwhelm what is left of the scruffy  dopey old hanna-barbera charm .\n",
      "\n",
      "88: what 's the most positive thing that can be said about the new rob schneider vehicle ?\n",
      "\n",
      "FUTURE SIMPLE\n",
      "89: the jokes are telegraphed so far in advance they must have been lost in the mail .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE PERFECT\n",
      "PRESENT PERFECT\n",
      "90: something has been lost in the translation ...\n",
      "PRESENT PERFECT\n",
      "91: another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise .\n",
      "\n",
      "92: but it is set in a world that is very  very far from the one most of us inhabit .\n",
      "\n",
      "93: the urban landscapes are detailed down to the signs on the kiosks  and the color palette  with lots of somber blues and pinks  is dreamy and evocative .\n",
      "\n",
      "94: so mind-numbingly awful that you hope britney wo n't do it one more time  as far as movies are concerned .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "95: slack and uninspired  and peopled mainly by characters so unsympathetic that you 're left with a sour taste in your mouth .\n",
      "\n",
      "96: it gets bogged down by hit-and-miss topical humour before getting to the truly good stuff .\n",
      "\n",
      "97: what more can be expected from a college comedy that 's target audience has n't graduated from junior high school ?\n",
      "\n",
      "FUTURE SIMPLE\n",
      "PRESENT PERFECT\n",
      "98: this may be the first cartoon ever to look as if it were being shown on the projection television screen of a sports bar .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "PAST CONTINUOUS\n",
      "99: it 's clear why deuces wild  which was shot two years ago  has been gathering dust on mgm 's shelf .\n",
      "\n",
      "PRESENT PERFECT CONTINUOUS\n",
      "100: how much you are moved by the emotional tumult of ( franÃ§ois and michÃ¨le 's ) relationship depends a lot on how interesting and likable you find them .\n",
      "\n",
      "101: the whole thing feels like a ruse  a tactic to cover up the fact that the picture is constructed around a core of flimsy -- or  worse yet  nonexistent -- ideas .\n",
      "\n",
      "102: equilibrium is what george orwell might have imagined\n",
      "FUTURE SIMPLE\n",
      "103: had today 's mood-altering drug therapy been envisioned by chemists in 1949 .\n",
      "\n",
      "104: as if drop dead gorgeous was n't enough  this equally derisive clunker is fixated on the spectacle of small-town competition .\n",
      "\n",
      "105: it 's so badly made on every level that i 'm actually having a hard time believing people were paid to make it .\n",
      "\n",
      "106: it 's anchored by splendid performances from an honored screen veteran and a sparkling newcomer who instantly transform themselves into a believable mother\\/daughter pair .\n",
      "\n",
      "107: some movies were made for the big screen  some for the small screen  and some  like ballistic : ecks vs. sever  were made for the palm screen .\n",
      "\n",
      "108: it 's been made with an innocent yet fervid conviction that our hollywood has all but lost .\n",
      "\n",
      "109: while certain cues  like the happy music  suggest that this movie is supposed to warm our hearts  jeong-hyang lee 's film is just as likely to blacken that organ with cold vengefulness .\n",
      "\n",
      "110: the santa clause\n",
      "111: 2 's plot may sound like it was co-written by mattel executives and lobbyists for the tinsel industry .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "112: it 's hard to believe these jokers are supposed to have pulled off four similar kidnappings before .\n",
      "\n",
      "PRESENT PERFECT\n",
      "113: the humor is forced and heavy-handed  and occasionally simply unpleasant .\n",
      "\n",
      "114: a strong script  powerful direction and splendid production design allows us to be transported into the life of wladyslaw szpilman  who is not only a pianist  but a good human being .\n",
      "\n",
      "115: it was filled with shootings  \n",
      "116: beatings  and more cussing than you could shake a stick at .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "117: yet another entry in the sentimental oh-those-wacky-brits genre that was ushered in by the full monty and is still straining to produce another smash hit .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "118: it 's got some pretentious eye-rolling moments and it did n't entirely grab me  \n",
      "119: but there 's stuff here to like .\n",
      "\n",
      "120: ... you can be forgiven for realizing that you 've spent the past 20 minutes looking at your watch and waiting for frida to just die already .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "121: a sexy  peculiar and always entertaining costume drama set in renaissance spain  and\n",
      "122: the fact that it 's based on true events somehow makes it all the more compelling .\n",
      "\n",
      "123: it 's clotted with heavy-handed symbolism  dime-store psychology and endless scenic shots that make 105 minutes seem twice as long .\n",
      "\n",
      "124: if ever such a dependable concept was botched in execution  this is it .\n",
      "\n",
      "125: it 's hard to care about a film that proposes as epic tragedy the plight of a callow rich boy who is forced to choose between his beautiful  self-satisfied 22-year-old girlfriend and an equally beautiful  self-satisfied 18-year-old mistress .\n",
      "\n",
      "126: been there  \n",
      "127: done that  liked it much better the first time around - when it was called the professional .\n",
      "\n",
      "128: matthew lillard is born to play shaggy !\n",
      "\n",
      "129: no amount of nostalgia for carvey 's glory days can disguise the fact that the new film is a lame kiddie flick and that carvey 's considerable talents are wasted in it .\n",
      "for a film that 's being advertised as a comedy  \n",
      "FUTURE SIMPLE\n",
      "130: sweet home alabama is n't as funny as you 'd hoped .\n",
      "\n",
      "131: it 's got the brawn  but not the brains .\n",
      "\n",
      "132: it 's supposed to be post-feminist breezy but ends up as tedious as the chatter of parrots raised on oprah .\n",
      "\n",
      "133: passable entertainment  \n",
      "134: but it 's the kind of motion picture that wo n't make much of a splash when it 's released  and will not be remembered long afterwards .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "135: instead of building to a laugh riot we are left with a handful of disparate funny moments of no real consequence .\n",
      "\n",
      "136: most fish stories are a little peculiar  \n",
      "137: but this is one that should be thrown back in the river .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "138: as warren he stumbles in search of all the emotions and life experiences he 's neglected over the years .\n",
      "\n",
      "139: what 's left is a rich stew of longing .\n",
      "\n",
      "140: a distinctly minor effort that will be seen to better advantage on cable  especially considering its barely feature-length running time of one hour .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FUTURE SIMPLE\n",
      "141: the story is so light and sugary that were it a macy 's thanksgiving day parade balloon  \n",
      "142: extra heavy-duty ropes would be needed to keep it from floating away .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "143: it 's not the least of afghan tragedies that this noble warlord would be consigned to the dustbin of history .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "144: freundlich 's made ( crudup ) a suburban architect  and a cipher .\n",
      "\n",
      "145: though there 's a clarity of purpose and even-handedness to the film 's direction  the drama feels rigged and sluggish .\n",
      "\n",
      "146: the audience when i saw this one was chuckling at all the wrong times  and that 's a bad sign when they 're supposed to be having a collective heart attack .\n",
      "\n",
      "PAST CONTINUOUS\n",
      "147: ... liotta is put in an impossible spot because his character 's deceptions ultimately undo him and the believability of the entire scenario .\n",
      "\n",
      "148: labute ca n't avoid a fatal mistake in the modern era : he 's changed the male academic from a lower-class brit to an american  a choice that upsets the novel 's exquisite balance and shreds the fabric of the film .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "149: harris is supposed to be the star of the story  but comes across as pretty dull and wooden .\n",
      "\n",
      "150: he 's worked too hard on this movie .\n",
      "\n",
      "151: a movie in which two not very absorbing characters are engaged in a romance you ca n't wait to see end .\n",
      "\n",
      "152: while much of the cast has charm -- especially allodi and nolden -- the performers are sunk by the film 's primitive approach to the mechanics of comedy .\n",
      "\n",
      "153: it 's a feature-length adaptation of one of those `` can this marriage be saved ? ''\n",
      "wells ' time machine was directed by h.g.\n",
      "\n",
      "154: a bonanza of wacky sight gags  outlandish color schemes  and corny visual puns that can be appreciated equally as an abstract frank tashlin comedy and as a playful recapitulation of the artist 's career .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "155: douglas mcgrath 's nicholas nickleby does dickens as it should be done cinematically .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "156: the dialogue is very choppy and monosyllabic despite the fact that it is being dubbed .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "157: there 's no point of view  \n",
      "158: no contemporary interpretation of joan 's prefeminist plight  \n",
      "159: so we 're left thinking the only reason to make the movie is because present standards allow for plenty of nudity .\n",
      "\n",
      "160: the rare movie that 's as crisp and to the point as the novel on which it 's based .\n",
      "\n",
      "161: suffocated by its fussy script and uptight characters  this musty adaptation is all the more annoying since it 's been packaged and sold back to us by hollywood .\n",
      "\n",
      "162: seagal is painfully foolish in trying to hold onto what 's left of his passe ' chopsocky glory .\n",
      "except as an acting exercise or an exceptionally dark joke  you wonder what anyone saw in this film that allowed it to get made .\n",
      "\n",
      "163: each story is built on a potentially interesting idea  but the first two are ruined by amateurish writing and acting  while the third feels limited by its short running time .\n",
      "by no means a slam-dunk and sure to ultimately disappoint the action fans who will be moved to the edge of their seats by the dynamic first act  \n",
      "FUTURE SIMPLE\n",
      "164: it still comes off as a touching  transcendent love story .\n",
      "\n",
      "165: such a bad movie that its luckiest viewers will be seated next to one of those ignorant pinheads who talk throughout the show .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "166: all in all  the count of monte cristo is okay  \n",
      "167: but it is surely no classic  like the novel upon which it is based .\n",
      "\n",
      "168: has not so much been written as assembled  frankenstein-like  out of other  marginally better shoot-em-ups .\n",
      "\n",
      "169: you might be shocked to discover that seinfeld 's real life is boring .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "PRESENT CONTINUOUS\n",
      "170: everything is pegged into the groove of a new york dating comedy with ` issues ' to simplify .\n",
      "\n",
      "171: the production has been made with an enormous amount of affection  \n",
      "PRESENT PERFECT\n",
      "172: so we believe these characters love each other .\n",
      "\n",
      "173: it 's a gag that 's worn a bit thin over the years  \n",
      "174: though do n't ask still finds a few chuckles .\n",
      "with lines that feel like long soliloquies -- even as they are being framed in conversation -- max is static  stilted .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "175: an achingly enthralling premise  \n",
      "176: the film is hindered by uneven dialogue and plot lapses .\n",
      "\n",
      "177: since the movie is based on a nicholas sparks best seller  \n",
      "178: you know death is lurking around the corner  just waiting to spoil things .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "179: though it was made with careful attention to detail and is well-acted by james spader and maggie gyllenhaal  \n",
      "180: i felt disrespected .\n",
      "\n",
      "181: the chÃ¢teau would have been benefited from a sharper  cleaner script before it went in front of the camera .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE PERFECT\n",
      "PRESENT PERFECT\n",
      "182: it 's mired in a shabby script that piles layer upon layer of action man clichÃ© atop wooden dialogue and a shifting tone that falls far short of the peculiarly moral amorality of ( woo 's ) best work .\n",
      "\n",
      "183: while the story is better-focused than the incomprehensible anne rice novel it 's based upon  \n",
      "184: queen of the damned is a pointless  meandering celebration of the goth-vampire  tortured\n",
      "185: woe-is-me lifestyle .\n",
      "\n",
      "186: the only young people who possibly will enjoy it are infants ... who might be distracted by the movie 's quick movements and sounds .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "187: five screenwriters are credited with the clichÃ©-laden screenplay ; it seems as if each watered down the version of the one before .\n",
      "\n",
      "188: i felt sad for lise not so much because of what happens as because she was captured by this movie when she obviously belongs in something lighter and sunnier  by rohmer  for example .\n",
      "\n",
      "189: bartlett 's hero remains a reactive cipher  when opening the man 's head and heart is the only imaginable reason for the film to be made .\n",
      "\n",
      "190: the film was produced by jerry bruckheimer and directed by joel schumacher  and reflects the worst of their shallow styles : wildly overproduced  inadequately motivated every step of the way and demographically targeted to please every one ( and no one ) .\n",
      "\n",
      "191: a fascinating case study of flower-power liberation -- and the price that was paid for it .\n",
      "\n",
      "192: almost as offensive as `` freddy got fingered . ''\n",
      "barney 's ideas about creation and identity do n't really seem all that profound  at least by way of what can be gleaned from this three-hour endurance test built around an hour 's worth of actual material .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "193: a sugar-coated rocky whose valuable messages are forgotten 10 minutes after the last trombone honks .\n",
      "\n",
      "194: the storylines are woven together skilfully  the magnificent swooping aerial shots are breathtaking  and the overall experience is awesome .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "195: the year 's greatest adventure  and jackson 's limited but enthusiastic adaptation has made literature literal without killing its soul --\n",
      "PRESENT PERFECT\n",
      "196: a feat any thinking person is bound to appreciate .\n",
      "\n",
      "197: every joke is repeated at least -- annoying  is n't it ?\n",
      "\n",
      "198: i ca n't remember the last time i saw an audience laugh so much during a movie  \n",
      "FUTURE SIMPLE\n",
      "199: but there 's only one problem ...\n",
      "200: it 's supposed to be a drama .\n",
      "\n",
      "201: it 's replaced by some dramatic scenes that are jarring and deeply out of place in what could have ( and probably should have ) been a lighthearted comedy .\n",
      "\n",
      "PRESENT CONTINUOUS\n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "202: this is a fragmented film  once a good idea that was followed by the bad idea to turn it into a movie .\n",
      "\n",
      "203: the movie should be credited with remembering his victims .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "204: the film is undone by anachronistic quick edits and occasional jarring glimpses of a modern theater audience watching the events unfold .\n",
      "...\n",
      "205: the picture 's cleverness is ironically muted by the very people who are intended to make it shine .\n",
      "\n",
      "206: sodden and glum  even in those moments where it 's supposed to feel funny and light .\n",
      "\n",
      "207: the film does n't show enough of the creative process or even of what was created for the non-fan to figure out what makes wilco a big deal .\n",
      "\n",
      "208: yet another iteration of what 's become one of the movies ' creepiest conventions  in which the developmentally disabled are portrayed with almost supernatural powers to humble  teach and ultimately redeem their mentally `` superior '' friends  family ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "209: although no pastry is violated  this nasty comedy pokes fun at the same easy targets as other rowdy raunch-fests -- farts  boobs  \n",
      "210: unmentionables -- without much success .\n",
      "\n",
      "211: if you do n't flee  you might be seduced .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "212: it 's supposed to be a romantic comedy - it suffers from too much norma rae and not enough pretty woman .\n",
      "\n",
      "213: that is made almost impossible by events that set the plot in motion .\n",
      "\n",
      "214: the inhospitability of the land emphasizes the spare precision of the narratives and helps to give them an atavistic power  as if they were tales that had been handed down since the beginning of time .\n",
      "\n",
      "PAST PERFECT\n",
      "215: the film is weighed down by supporting characters who are either too goodly  wise and knowing or downright comically evil .\n",
      "\n",
      "216: naipaul fans may be disappointed .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "217: a `` home alone '' film that is staged like `` rosemary 's baby  ''\n",
      "218: but is not as well-conceived as either of those films .\n",
      "\n",
      "219: the best thing that can be said of the picture is that it does have a few cute moments .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "220: the film is based on truth and yet there is something about it that feels incomplete  as if the real story starts just around the corner .\n",
      "\n",
      "221: the 1960s rebellion was misdirected : you ca n't fight your culture .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "222: it would be churlish to begrudge anyone for receiving whatever consolation that can be found in dragonfly  \n",
      "FUTURE SIMPLE\n",
      "FUTURE SIMPLE\n",
      "223: yet it is impossible to find the film anything but appalling  shamelessly manipulative and contrived  and totally lacking in conviction .\n",
      "\n",
      "224: i would be shocked if there was actually one correct interpretation  \n",
      "FUTURE SIMPLE\n",
      "225: but that should n't make the movie or the discussion any less enjoyable .\n",
      "at its best  \n",
      "FUTURE SIMPLE\n",
      "226: this is grand-scale moviemaking for a larger-than-life figure  \n",
      "227: an artist who has been awarded mythic status in contemporary culture .\n",
      "\n",
      "PRESENT PERFECT\n",
      "228: it does nothing new with the old story  except to show fisticuffs in this sort of stop-go slow motion that makes the gang rumbles look like they 're being streamed over a 28k modem .\n",
      "\n",
      "229: the characters are based on stock clichÃ©s  and the attempt to complicate the story only defies credibility .\n",
      "\n",
      "230: evelyn may be based on a true and historically significant story  but the filmmakers have made every effort to disguise it as an unimaginative screenwriter 's invention .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "PRESENT PERFECT\n",
      "231: like a soft drink that 's been sitting open too long : it 's too much syrup and not enough fizz .\n",
      "\n",
      "232: even though it is infused with the sensibility of a video director  \n",
      "233: it does n't make for completely empty entertainment\n",
      "the story itself it mostly told through on-camera interviews with several survivors  whose riveting memories are rendered with such clarity that it 's as if it all happened only yesterday .\n",
      "\n",
      "234: the film is hampered by its predictable plot and paper-thin supporting characters .\n",
      "\n",
      "235: it follows the blair witch formula for an hour  in which we 're told something creepy and\n",
      "236: vague is in the works  \n",
      "237: and then it goes awry in the final 30 minutes .\n",
      "\n",
      "238: imagine kevin\n",
      "239: smith  the blasphemous bad boy of suburban jersey  if he were stripped of most of his budget and all of his sense of humor .\n",
      "\n",
      "240: it 's not just the vampires that are damned in queen of the damned -- the viewers will feel they suffer the same fate .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "241: something must have been lost in the translation .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE PERFECT\n",
      "PRESENT PERFECT\n",
      "242: the movie could have been made 40 years ago  and parents ' appreciation of it may depend on whether they consider that a good thing .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "FUTURE PERFECT\n",
      "PRESENT PERFECT\n",
      "FUTURE SIMPLE\n",
      "243: even bigger and more ambitious than the first installment  spy kids 2 looks as if it were made by a highly gifted 12-year-old instead of a grown man .\n",
      "\n",
      "244: in the new guy  even the bull gets recycled .\n",
      "\n",
      "245: like most movies about the pitfalls of bad behavior ... circuit gets drawn into the party .\n",
      "-- that the ` true story ' by which all the queen 's men is allegedly `` inspired '' was a lot funnier and more deftly enacted than what 's been cobbled together onscreen .\n",
      "\n",
      "246: a movie like the guys is why film criticism can be considered work .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "247: rather than real figures  elling and kjell bjarne become symbolic characters whose actions are supposed to relate something about the naÃ¯f 's encounter with the world .\n",
      "\n",
      "248: the issues are presented in such a lousy way  complete with some of the year 's ( unintentionally ) funniest moments  that it 's impossible to care .\n",
      "\n",
      "249: the images are usually abbreviated in favor of mushy obviousness and telegraphed pathos  particularly where whitaker 's misfit artist is concerned .\n",
      "\n",
      "250: pacino is the best he 's been in years and keener is marvelous .\n",
      "\n",
      "251: a film that should be relegated to a dark video store corner is somehow making its way instead to theaters .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "PRESENT CONTINUOUS\n",
      "252: many of benjamins ' elements feel like they 've been patched in from an episode of miami vice .\n",
      "\n",
      "253: for close to two hours the audience is forced to endure three terminally depressed  mostly inarticulate  hyper dysfunctional families for the price of one .\n",
      "\n",
      "254: although god is great addresses interesting matters of identity and heritage  \n",
      "255: it 's hard to shake the feeling that it was intended to be a different kind of film .\n",
      "\n",
      "256: i was sent a copyof this film to review on dvd .\n",
      "\n",
      "257: any intellectual arguments being made about the nature of god are framed in a drama so clumsy  \n",
      "258: there is a real danger less sophisticated audiences will mistake it for an endorsement of the very things that bean abhors .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "259: they 're going through the motions  but the zip is gone .\n",
      "\n",
      "260: the merchant-ivory team continues to systematically destroy everything we hold dear about cinema  \n",
      "261: only now it 's begun to split up so that it can do even more damage .\n",
      "\n",
      "FUTURE SIMPLE\n",
      "262: the entire movie is filled with deja vu moments .\n",
      "\n",
      "263: it 's been done before but never so vividly or with so much passion .\n",
      "like a fish that 's lived too long  austin powers in goldmember has some unnecessary parts and is kinda wrong in places .\n",
      "...\n",
      "264: the movie feels stitched together from stock situations and characters from other movies .\n",
      "\n",
      "265: the jokes are sophomoric  stereotypes are sprinkled everywhere and the acting ranges from bad to bodacious .\n",
      "as gory as the scenes of torture and self-mutilation may be  \n",
      "FUTURE SIMPLE\n",
      "266: they are pitted against shimmering cinematography that lends the setting the ethereal beauty of an asian landscape painting .\n",
      "\n",
      "267: this angst-ridden territory was covered earlier and much better in ordinary people .\n",
      "\n",
      "268: thanks largely to williams  all the interesting developments are processed in 60 minutes -- the rest is just an overexposed waste of film .\n",
      "\n",
      "269: it is most of the things costner movies are known for ; it 's sanctimonious  self-righteous and so eager to earn our love that you want to slap it .\n",
      "\n",
      "84\n",
      "269\n"
     ]
    }
   ],
   "source": [
    "#PRESENT PERFECT CONTINUOUS\n",
    "from spacy.matcher import Matcher\n",
    "def on_matchppct(matcher, doc, id, matches):\n",
    "    print(\"PRESENT PERFECT CONTINUOUS\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('PPCT',on_matchppct,[{\"LOWER\": \"has\"},{\"LOWER\": \"been\"},{'TAG':'VBG'}])\n",
    "matcher.add('PPCT',on_matchppct,[{'TAG':'MD','OP':'!'},{\"LOWER\": \"have\"},{\"LOWER\": \"been\"},{'TAG':'VBG'}])\n",
    "\n",
    "#PRESENT PERFECT\n",
    "def on_matchppt(matcher, doc, id, matches):\n",
    "    print(\"PRESENT PERFECT\")\n",
    "matcher.add('PPT',on_matchppt,[{\"LOWER\": \"has\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'TAG':'VBN'},{'TAG':'VBG','OP':'!'}])\n",
    "matcher.add('PPT',on_matchppt,[{\"LOWER\": \"have\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'TAG':'VBN'},{'TAG':'VBG','OP':'!'}])\n",
    "\n",
    "#PRESENT CONTINUOUS\n",
    "def on_matchpc(matcher, doc, id, matches):\n",
    "        print(\"PRESENT CONTINUOUS\")\n",
    "matcher.add('PCTense',on_matchpc,[{\"LOWER\": \"is\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'POS':'ADV','OP':'?'},{'TAG':'VBG'}])\n",
    "matcher.add('PCTense',on_matchpc,[{\"LOWER\": \"am\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'POS':'ADV','OP':'?'},{'TAG':'VBG'}])\n",
    "matcher.add('PCTense',on_matchpc,[{\"LOWER\": \"are\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'POS':'ADV','OP':'?'},{'TAG':'VBG'}])\n",
    "\n",
    "#PAST PERFECT\n",
    "def on_match_pastperf(matcher, doc, id, matches):\n",
    "    print(\"PAST PERFECT\")\n",
    "matcher.add('PASTPERF',on_match_pastperf,[{\"TEXT\":\"had\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'POS':'ADV','OP':'?'},{'TAG':'VBN'},{'TAG':'VBG','OP':'!'}])\n",
    "\n",
    "#PAST CONTINUOUS\n",
    "def on_match_pastcont(matcher, doc, id,matches):\n",
    "    print(\"PAST CONTINUOUS\")\n",
    "matcher.add('PASTCONT',on_match_pastcont,[{\"LOWER\":\"was\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'POS':'ADV','OP':'?'},{'TAG':'VBG'}])\n",
    "matcher.add('PASTCONT',on_match_pastcont,[{\"LOWER\":\"were\"},{'DEP':'neg','OP':'?'},{'DEP':'nsubj','OP':'?'},{'POS':'ADV','OP':'?'},{'TAG':'VBG'}])\n",
    "\n",
    "#PAST PERFECT CONTINUOUS\n",
    "def on_match_pastpc(matcher, doc, id, matches):\n",
    "    print(\"PAST PERFECT CONTINUOUS\")\n",
    "matcher.add('PASTPC',on_match_pastpc,[{\"LOWER\":\"had\"},{'DEP':'neg','OP':'?'},{\"LOWER\":\"been\"},{'TAG':'VBG'}])\n",
    "matcher.add('PASTPC',on_match_pastpc,[{\"LOWER\":\"had\"},{'DEP':'det','OP':'?'},{'DEP':'nsubj','OP':'?'},{\"LOWER\":\"been\"},{'TAG':'VBG'}])\n",
    "\n",
    "#FUTURE SIMPLE\n",
    "def on_match_futsim(matcher, doc, id, matches):\n",
    "    print(\"FUTURE SIMPLE\")\n",
    "matcher.add('FUTSIM',on_match_futsim,[{'TAG':'MD'},{'DEP':'nsubj','OP':'?'},{'DEP':'neg','OP':'?'},{'TAG':'VB'},{'DEP':'aux','OP':'!'}])\n",
    "\n",
    "#FUTURE CONTINUOUS\n",
    "def on_match_futcont(matcher, doc, id, matches):\n",
    "    print(\"FUTURE CONTINUOUS\")\n",
    "matcher.add('FUTCONT',on_match_futcont,[{'TAG':'MD'},{'DEP':'nsubj','OP':'?'},{'DEP':'neg','OP':'?'},{\"LOWER\":\"be\"},{'TAG':'VBG'}])\n",
    "\n",
    "#FUTURE PERFECT\n",
    "def on_match_futperf(matcher, doc, id, matches):\n",
    "    print(\"FUTURE PERFECT\")\n",
    "matcher.add('FUTPERF',on_match_futperf,[{'TAG':'MD'},{'DEP':'nsubj','OP':'?'},{'DEP':'neg','OP':'?'},{\"LOWER\":\"have\"},{'TAG':'VBN'},{'TAG':'VBG','OP':'!'}])\n",
    "\n",
    "#FUTURE PERFECT CONTINUOUS\n",
    "def on_match_futpc(matcher, doc, id, matches):\n",
    "    print(\"FUTURE PERFECT CONTINUOUS\")\n",
    "matcher.add('FUTPC',on_match_futpc,[{'TAG':'MD'},{'DEP':'nsubj','OP':'?'},{'DEP':'neg','OP':'?'},{\"LOWER\":\"have\"},{\"LOWER\":\"been\"},{'TAG':'VBG'}])\n",
    "\n",
    "#------------------------------------------*****-----------------------------------------#\n",
    "\n",
    "dd = nlp(\"He will not buy a car. They will have been living in Paris for five years \")\n",
    "# ding = nlp(\"He has been reading the book for two hours.\")\n",
    "# dong = nlp(\"He has finished his homework.\")\n",
    "\n",
    "hit = 0\n",
    "\n",
    "#sentence input\n",
    "for num,sentence in enumerate(nlp(d_text1).sents):\n",
    "    print(f'{num}: {sentence}')\n",
    "    s = sentence.as_doc()\n",
    "    if(matcher(s)):\n",
    "        hit += 1\n",
    "\n",
    "print(hit)\n",
    "print(num)\n",
    "\n",
    "#tense_form(\"He has finished his homework.\")\n",
    "#tense_form(dong)\n",
    "#matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"He has been reading the book for two hours. He has finished his homework.\"\n",
    "doc = nlp(raw_text)\n",
    "sentences = [sent.string.strip() for sent in doc.sents]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"sentence : \",sentence)\n",
    "    doc = nlp(sentence)\n",
    "    tense_form(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Emoji\n",
    "\n",
    "Using the python package \"spacymoji\"\n",
    ">`pip install spacymoji`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"assert doc[2:5]._.has_emoji == True\\nassert doc[0]._.is_emoji == False\\nassert doc[4]._.is_emoji == True\\nassert doc[5]._.emoji_desc == u'thumbs up dark skin tone'\\nassert len(doc._.emoji) == 2\\nassert doc._.emoji[1] == (u'👍🏿', 5, u'thumbs up dark skin tone')\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacymoji import Emoji\n",
    "\n",
    "emoji = Emoji(nlp)\n",
    "#nlp.add_pipe(emoji, first=True)\n",
    "doc = nlp(u\"This is a test 😻 👍🏿\")\n",
    "#assert doc._.has_emoji == True\n",
    "\"\"\"assert doc[2:5]._.has_emoji == True\n",
    "assert doc[0]._.is_emoji == False\n",
    "assert doc[4]._.is_emoji == True\n",
    "assert doc[5]._.emoji_desc == u'thumbs up dark skin tone'\n",
    "assert len(doc._.emoji) == 2\n",
    "assert doc._.emoji[1] == (u'👍🏿', 5, u'thumbs up dark skin tone')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Using an LSTM sentiment classification model trained using Keras in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example shows how to use an LSTM sentiment classification model trained\n",
    "using Keras in spaCy. spaCy splits the document into sentences, and each\n",
    "sentence is classified using the LSTM. The scores for the sentences are then\n",
    "aggregated to give the document score. This kind of hierarchical model is quite\n",
    "difficult in \"pure\" Keras or Tensorflow, but it's very effective. The Keras\n",
    "example on this dataset performs quite poorly, because it cuts off the documents\n",
    "so that they're a fixed size. This hurts review accuracy a lot, because people\n",
    "often summarise their rating in the final sentence\n",
    "\n",
    "Prerequisites:\n",
    "spacy download en_vectors_web_lg\n",
    "pip install keras==2.0.9\n",
    "\n",
    "Compatible with: spaCy v2.0.0+\n",
    "\"\"\"\n",
    "\n",
    "import plac\n",
    "import random\n",
    "import pathlib\n",
    "import cytoolz\n",
    "import numpy\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "import thinc.extra.datasets\n",
    "from spacy.compat import pickle\n",
    "import spacy\n",
    "\n",
    "\n",
    "class SentimentAnalyser(object):\n",
    "    @classmethod\n",
    "    def load(cls, path, nlp, max_length=100):\n",
    "        with (path / \"config.json\").open() as file_:\n",
    "            model = model_from_json(file_.read())\n",
    "        with (path / \"model\").open(\"rb\") as file_:\n",
    "            lstm_weights = pickle.load(file_)\n",
    "        embeddings = get_embeddings(nlp.vocab)\n",
    "        model.set_weights([embeddings] + lstm_weights)\n",
    "        return cls(model, max_length=max_length)\n",
    "\n",
    "    def __init__(self, model, max_length=100):\n",
    "        self._model = model\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        X = get_features([doc], self.max_length)\n",
    "        y = self._model.predict(X)\n",
    "        self.set_sentiment(doc, y)\n",
    "\n",
    "    def pipe(self, docs, batch_size=1000):\n",
    "        for minibatch in cytoolz.partition_all(batch_size, docs):\n",
    "            minibatch = list(minibatch)\n",
    "            sentences = []\n",
    "            for doc in minibatch:\n",
    "                sentences.extend(doc.sents)\n",
    "            Xs = get_features(sentences, self.max_length)\n",
    "            ys = self._model.predict(Xs)\n",
    "            for sent, label in zip(sentences, ys):\n",
    "                sent.doc.sentiment += label - 0.5\n",
    "            for doc in minibatch:\n",
    "                yield doc\n",
    "\n",
    "    def set_sentiment(self, doc, y):\n",
    "        doc.sentiment = float(y[0])\n",
    "        # Sentiment has a native slot for a single float.\n",
    "        # For arbitrary data storage, there's:\n",
    "        # doc.user_data['my_data'] = y\n",
    "\n",
    "\n",
    "def get_labelled_sentences(docs, doc_labels):\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    for doc, y in zip(docs, doc_labels):\n",
    "        for sent in doc.sents:\n",
    "            sentences.append(sent)\n",
    "            labels.append(y)\n",
    "    return sentences, numpy.asarray(labels, dtype=\"int32\")\n",
    "\n",
    "\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = numpy.zeros((len(docs), max_length), dtype=\"int32\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    dev_texts,\n",
    "    dev_labels,\n",
    "    lstm_shape,\n",
    "    lstm_settings,\n",
    "    lstm_optimizer,\n",
    "    batch_size=100,\n",
    "    nb_epoch=5,\n",
    "    by_sentence=True,\n",
    "):\n",
    "\n",
    "    print(\"Loading spaCy\")\n",
    "    nlp = spacy.load(\"en_vectors_web_lg\")\n",
    "    nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
    "    embeddings = get_embeddings(nlp.vocab)\n",
    "    model = compile_lstm(embeddings, lstm_shape, lstm_settings)\n",
    "\n",
    "    print(\"Parsing texts...\")\n",
    "    train_docs = list(nlp.pipe(train_texts))\n",
    "    dev_docs = list(nlp.pipe(dev_texts))\n",
    "    if by_sentence:\n",
    "        train_docs, train_labels = get_labelled_sentences(train_docs, train_labels)\n",
    "        dev_docs, dev_labels = get_labelled_sentences(dev_docs, dev_labels)\n",
    "\n",
    "    train_X = get_features(train_docs, lstm_shape[\"max_length\"])\n",
    "    dev_X = get_features(dev_docs, lstm_shape[\"max_length\"])\n",
    "    model.fit(\n",
    "        train_X,\n",
    "        train_labels,\n",
    "        validation_data=(dev_X, dev_labels),\n",
    "        epochs=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_lstm(embeddings, shape, settings):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            embeddings.shape[0],\n",
    "            embeddings.shape[1],\n",
    "            input_length=shape[\"max_length\"],\n",
    "            trainable=False,\n",
    "            weights=[embeddings],\n",
    "            mask_zero=True,\n",
    "        )\n",
    "    )\n",
    "    model.add(TimeDistributed(Dense(shape[\"nr_hidden\"], use_bias=False)))\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                shape[\"nr_hidden\"],\n",
    "                recurrent_dropout=settings[\"dropout\"],\n",
    "                dropout=settings[\"dropout\"],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    model.add(Dense(shape[\"nr_class\"], activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=settings[\"lr\"]),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_embeddings(vocab):\n",
    "    return vocab.vectors.data\n",
    "\n",
    "\n",
    "def evaluate(model_dir, texts, labels, max_length=100):\n",
    "    nlp = spacy.load(\"en_vectors_web_lg\")\n",
    "    nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
    "    nlp.add_pipe(SentimentAnalyser.load(model_dir, nlp, max_length=max_length))\n",
    "\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    for doc in nlp.pipe(texts, batch_size=1000):\n",
    "        correct += bool(doc.sentiment >= 0.5) == bool(labels[i])\n",
    "        i += 1\n",
    "    return float(correct) / i\n",
    "\n",
    "\n",
    "def read_data(data_dir, limit=0):\n",
    "    examples = []\n",
    "    for subdir, label in ((\"pos\", 1), (\"neg\", 0)):\n",
    "        for filename in (data_dir / subdir).iterdir():\n",
    "            with filename.open() as file_:\n",
    "                text = file_.read()\n",
    "            examples.append((text, label))\n",
    "    random.shuffle(examples)\n",
    "    if limit >= 1:\n",
    "        examples = examples[:limit]\n",
    "    return zip(*examples)  # Unzips into two lists\n",
    "\n",
    "\n",
    "@plac.annotations(\n",
    "    train_dir=(\"Location of training file or directory\"),\n",
    "    dev_dir=(\"Location of development file or directory\"),\n",
    "    model_dir=(\"Location of output model directory\",),\n",
    "    is_runtime=(\"Demonstrate run-time usage\", \"flag\", \"r\", bool),\n",
    "    nr_hidden=(\"Number of hidden units\", \"option\", \"H\", int),\n",
    "    max_length=(\"Maximum sentence length\", \"option\", \"L\", int),\n",
    "    dropout=(\"Dropout\", \"option\", \"d\", float),\n",
    "    learn_rate=(\"Learn rate\", \"option\", \"e\", float),\n",
    "    nb_epoch=(\"Number of training epochs\", \"option\", \"i\", int),\n",
    "    batch_size=(\"Size of minibatches for training LSTM\", \"option\", \"b\", int),\n",
    "    nr_examples=(\"Limit to N examples\", \"option\", \"n\", int),\n",
    ")\n",
    "def main(\n",
    "    model_dir=None,\n",
    "    train_dir=None,\n",
    "    dev_dir=None,\n",
    "    is_runtime=False,\n",
    "    nr_hidden=64,\n",
    "    max_length=100,  # Shape\n",
    "    dropout=0.5,\n",
    "    learn_rate=0.001,  # General NN config\n",
    "    nb_epoch=5,\n",
    "    batch_size=256,\n",
    "    nr_examples=-1,\n",
    "):  # Training params\n",
    "    if model_dir is not None:\n",
    "        model_dir = pathlib.Path(model_dir)\n",
    "    if train_dir is None or dev_dir is None:\n",
    "        imdb_data = thinc.extra.datasets.imdb()\n",
    "    if is_runtime:\n",
    "        if dev_dir is None:\n",
    "            dev_texts, dev_labels = zip(*imdb_data[1])\n",
    "        else:\n",
    "            dev_texts, dev_labels = read_data(dev_dir)\n",
    "        acc = evaluate(model_dir, dev_texts, dev_labels, max_length=max_length)\n",
    "        print(acc)\n",
    "    else:\n",
    "        if train_dir is None:\n",
    "            train_texts, train_labels = zip(*imdb_data[0])\n",
    "        else:\n",
    "            print(\"Read data\")\n",
    "            train_texts, train_labels = read_data(train_dir, limit=nr_examples)\n",
    "        if dev_dir is None:\n",
    "            dev_texts, dev_labels = zip(*imdb_data[1])\n",
    "        else:\n",
    "            dev_texts, dev_labels = read_data(dev_dir, imdb_data, limit=nr_examples)\n",
    "        train_labels = numpy.asarray(train_labels, dtype=\"int32\")\n",
    "        dev_labels = numpy.asarray(dev_labels, dtype=\"int32\")\n",
    "        lstm = train(\n",
    "            train_texts,\n",
    "            train_labels,\n",
    "            dev_texts,\n",
    "            dev_labels,\n",
    "            {\"nr_hidden\": nr_hidden, \"max_length\": max_length, \"nr_class\": 1},\n",
    "            {\"dropout\": dropout, \"lr\": learn_rate},\n",
    "            {},\n",
    "            nb_epoch=nb_epoch,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        weights = lstm.get_weights()\n",
    "        if model_dir is not None:\n",
    "            with (model_dir / \"model\").open(\"wb\") as file_:\n",
    "                pickle.dump(weights[1:], file_)\n",
    "            with (model_dir / \"config.json\").open(\"w\") as file_:\n",
    "                file_.write(lstm.to_json())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plac.call(main)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
